apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: "sd-finetune-"
spec:
  entrypoint: main
  arguments:
    parameters:
    # run_name should be unique on a per-run basis, especially if reporting
    # to wandb or sharing PVCs between runs.
    - name: run_name
    - name: pvc
      value: 'sd-finetune-data'
    # Training parameters. Model IDs are hugging face IDs to pull down, or
    # a path to your Diffusers model relative to the PVC root.
    - name: model
      value: 'runwayml/stable-diffusion-v1-5'
    # The directory to read your dataset in.
    - name: dataset
      value: 'dataset'
    # The learning rate to use.
    - name: lr
      value: '5e-6'
    # The amount of epochs to use.
    - name: epochs
      value: '10'
    # Batch size
    - name: batch_size
      value: '1'
    # Whether or not to use EMA (Exponential Moving Average) for the model during training.
    - name: use_ema
      value: 'False'
    # Whether or not to use Gradient Checkpointing. This is a memory optimization that trades off compute for memory.
    - name: gradient_checkpointing
      value: 'False'
    # 8-bit Adam Optimizer - Only works on certain GPUs.
    - name: use_8bit_adam
      value: 'False'
    # Adam beta 1
    - name: adam_beta1
      value: '0.9'
    # Adam beta 2
    - name: adam_beta2
      value: '0.999'
    # Adam weight decay
    - name: adam_weight_decay
      value: '1e-2'
    # Adam epsilon
    - name: adam_epsilon
      value: '1e-8'
    # Seed for reproducibility
    - name: seed
      value: '42'
    # Checkpointing steps to save the model at.
    - name: save_steps
      value: '500'
    # Image resolution to train at
    - name: resolution
      value: '512'
    # Whether or not to resize the images during training.
    - name: resize
      value: 'False'
    # Center crop the images during training.
    - name: center_crop
      value: 'False'
    # Resizing interpolation method.
    - name: resize_interp
      value: 'lanczos'
    # Whether or not to shuffle the dataset.
    - name: shuffle
      value: 'True'
    # Image logging steps to log images at.
    - name: image_log_steps
      value: '500'
    # Amount of images to log at every image logging step.
    - name: image_log_amount
      value: '4'
    # Huggingface Token to download CompVis models.
    - name: hf_token
    # Wandb API key to report to wandb.
    - name: wandb_api_key
    # Project ID to report to wandb.
    - name: project_id
      value: 'sd-finetune'
    # Run a serialization step after finetuning and deserialize it when starting the inference service.
    # Provides significant performance increase in start up times of inference pods
    - name: use_tensorizer
      value: true
    # Inference service configuration.
    - name: run_inference
      value: false
    # Skip training and only run inference.
    - name: inference_only
      value: false
    # CoreWeave region to default to; ORD1 has most of the GPUs.
    - name: region
      value: 'ORD1'
    # Training GPU - A6000, 48gb VRAM
    - name: trainer_gpu
      value: 'RTX_A6000'
    - name: trainer_gpu_count
      value: '1'
    # Inference GPU - Quadro RTX 5000, 16gb VRAM
    - name: inference_gpu
      value: 'Quadro_RTX_5000'
    # Container images -- generally, don't alter this.
    - name: downloader_image
      value: 'ghcr.io/wbrown/gpt_bpe/model_downloader'
    - name: downloader_tag
      value: 'e526c65'
    - name: finetuner_image
      value: 'navarrepratt/sd-finetuner'  # TODO: Update with CoreWeave hosted image
    - name: finetuner_tag
      value: 'dreambooth-12'
    - name: serializer_image
      value: 'navarrepratt/sd-serializer'  # TODO: Update with CoreWeave hosted image
    - name: serializer_tag
      value: '5'
    - name: inference_image
      value: 'navarrepratt/sd-inference'  # TODO: Update with CoreWeave hosted image
    - name: inference_tag
      value: '11'

  templates:
  - name: main
    steps:
    - - name: downloader
        template: model-downloader
        arguments:
          parameters:
            - name: model
              value: "{{workflow.parameters.model}}"
            - name: dest
              value: "/{{workflow.parameters.pvc}}/models/{{workflow.parameters.model}}"
            - name: type
              value: "diffusers"
        when: "{{workflow.parameters.inference_only}} == false"

    - - name: finetuner
        template: model-finetuner
        arguments:
          parameters:
          - name: gpu_count
            value: "{{workflow.parameters.trainer_gpu_count}}"
          - name: run_name
            value: "{{workflow.parameters.run_name}}"
          - name: model
            value: "/{{workflow.parameters.pvc}}/models/{{workflow.parameters.model}}"
          - name: dataset
            value: "/{{workflow.parameters.pvc}}/{{workflow.parameters.dataset}}"
          - name: lr
            value: "{{workflow.parameters.lr}}"
          - name: epochs
            value: "{{workflow.parameters.epochs}}"
          - name: batch_size
            value: "{{workflow.parameters.batch_size}}"
          - name: use_ema
            value: "{{workflow.parameters.use_ema}}"
          - name: gradient_checkpointing
            value: "{{workflow.parameters.gradient_checkpointing}}"
          - name: use_8bit_adam
            value: "{{workflow.parameters.use_8bit_adam}}"
          - name: adam_beta1
            value: "{{workflow.parameters.adam_beta1}}"
          - name: adam_beta2
            value: "{{workflow.parameters.adam_beta2}}"
          - name: adam_weight_decay
            value: "{{workflow.parameters.adam_weight_decay}}"
          - name: adam_epsilon
            value: "{{workflow.parameters.adam_epsilon}}"
          - name: seed
            value: "{{workflow.parameters.seed}}"
          - name: output_path
            value: "/{{workflow.parameters.pvc}}/finetunes/{{workflow.parameters.run_name}}"
          - name: save_steps
            value: "{{workflow.parameters.save_steps}}"
          - name: resolution
            value: "{{workflow.parameters.resolution}}"
          - name: resize
            value: "{{workflow.parameters.resize}}"
          - name: center_crop
            value: "{{workflow.parameters.center_crop}}"
          - name: resize_interp
            value: "{{workflow.parameters.resize_interp}}"
          - name: shuffle
            value: "{{workflow.parameters.shuffle}}"
          - name: image_log_steps
            value: "{{workflow.parameters.image_log_steps}}"
          - name: image_log_amount
            value: "{{workflow.parameters.image_log_amount}}"
          - name: hf_token
            value: "{{workflow.parameters.hf_token}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
        when: "{{workflow.parameters.inference_only}} == false"

    - - name: serializer
        template: serializer
        arguments:
          parameters:
            - name: model
              value: "/{{workflow.parameters.pvc}}/finetunes/{{workflow.parameters.run_name}}"
            - name: output_path
              value: "/{{workflow.parameters.pvc}}/finetunes/{{workflow.parameters.run_name}}"
        when: "{{workflow.parameters.use_tensorizer}} == true && {{workflow.parameters.inference_only}} == false"
      
    - - name: inference
        template: model-inference-service
        arguments:
          parameters:
            - name: model_id
              value: "/mnt/pvc/finetunes/{{workflow.parameters.run_name}}"
            - name: hf_home
              value: ""
            - name: command
              value: '["python3", "/app/service.py"{{=workflow.parameters.use_tensorizer == "true" ? ", \"--tensorized\"" : ""}}]'
        when: "{{workflow.parameters.run_inference}} == true || {{workflow.parameters.inference_only}} == true"

  - name: model-downloader
    inputs:
      parameters:
        - name: model
        - name: dest
        - name: type
    retryStrategy:
      limit: 1
    # The model downloader runs as the nonroot user so the dataset folder in the PVC
    # needs the correct permissions.
    initContainers:
      - name: dataset-perms
        image: alpine:3.17
        command: [ "/bin/sh" ]
        args:
          - "-c"
          - "mkdir -p {{inputs.parameters.dest}};
            chmod o+rw,g+s {{inputs.parameters.dest}}"
        mirrorVolumeMounts: true
    container:
      image: "{{workflow.parameters.downloader_image}}:{{workflow.parameters.downloader_tag}}"
      command: ["/ko-app/model_downloader"]
      args: ["--model", "{{inputs.parameters.model}}",
             "--dest", "{{inputs.parameters.dest}}",
             "--type", "{{inputs.parameters.type}}"]
      env:
        - name: HF_API_TOKEN
          value: "{{workflow.parameters.hf_token}}"
      resources:
        requests:
          memory: 512Mi
          cpu: "2"
        limits:
          memory: 512Mi
          cpu: "2"
      volumeMounts:
        - mountPath: "/{{workflow.parameters.pvc}}"
          name: "{{workflow.parameters.pvc}}"
    volumes:
      - name: "{{workflow.parameters.pvc}}"
        persistentVolumeClaim:
           claimName: "{{workflow.parameters.pvc}}"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: topology.kubernetes.io/region
              operator: In
              values:
              - "{{workflow.parameters.region}}"

  - name: model-finetuner
    inputs:
      parameters:
        - name: gpu_count
        - name: run_name
        - name: model
        - name: dataset
        - name: lr
        - name: epochs
        - name: batch_size
        - name: use_ema
        - name: gradient_checkpointing
        - name: use_8bit_adam
        - name: adam_beta1
        - name: adam_beta2
        - name: adam_weight_decay
        - name: adam_epsilon
        - name: seed
        - name: output_path
        - name: save_steps
        - name: resolution
        - name: resize
        - name: center_crop
        - name: resize_interp
        - name: shuffle
        - name: image_log_steps
        - name: image_log_amount
        - name: hf_token
        - name: project_id
    container:
      image: "{{workflow.parameters.finetuner_image}}:{{workflow.parameters.finetuner_tag}}"
      command: [ "/usr/bin/python3",
                 "-m", "accelerate.commands.launch",
                 "--config", "/app/accelerate_config.yaml",
                 "--num_processes", "{{inputs.parameters.gpu_count}}",
                 "/app/finetuner.py" ]
      args: ["--run_name", "{{inputs.parameters.run_name}}",
              "--model", "{{inputs.parameters.model}}",
              "--dataset", "{{inputs.parameters.dataset}}",
              "--lr", "{{inputs.parameters.lr}}",
              "--epochs", "{{inputs.parameters.epochs}}",
              "--batch_size", "{{inputs.parameters.batch_size}}",
              "--use_ema", "{{inputs.parameters.use_ema}}",
              "--gradient_checkpointing", "{{inputs.parameters.gradient_checkpointing}}",
              "--use_8bit_adam", "{{inputs.parameters.use_8bit_adam}}",
              "--adam_beta1", "{{inputs.parameters.adam_beta1}}",
              "--adam_beta2", "{{inputs.parameters.adam_beta2}}",
              "--adam_weight_decay", "{{inputs.parameters.adam_weight_decay}}",
              "--adam_epsilon", "{{inputs.parameters.adam_epsilon}}",
              "--seed", "{{inputs.parameters.seed}}",
              "--output_path", "{{inputs.parameters.output_path}}",
              "--save_steps", "{{inputs.parameters.save_steps}}",
              "--resolution", "{{inputs.parameters.resolution}}",
              "--resize", "{{inputs.parameters.resize}}",
              "--center_crop", "{{inputs.parameters.center_crop}}",
              "--resize_interp", "{{inputs.parameters.resize_interp}}",
              "--shuffle", "{{inputs.parameters.shuffle}}",
              "--image_log_steps", "{{inputs.parameters.image_log_steps}}",
              "--image_log_amount", "{{inputs.parameters.image_log_amount}}",
              "--hf_token", "{{inputs.parameters.hf_token}}",
              "--project_id", "{{inputs.parameters.project_id}}"]
      tty: true
      env:
      - name: PYTHONUNBUFFERED
        value: "1"
      - name: WANDB_API_KEY
        value: "{{workflow.parameters.wandb_api_key}}"
      - name: GPU_COUNT
        value: "{{workflow.parameters.trainer_gpu_count}}"
      resources:
        requests:
          memory: 32Gi
          cpu: "8"
        limits:
          memory: 96Gi
          cpu: "16"
      volumeMounts:
        - mountPath: "/{{workflow.parameters.pvc}}"
          name: "{{workflow.parameters.pvc}}"
    volumes:
      - name: "{{workflow.parameters.pvc}}"
        persistentVolumeClaim:
           claimName: "{{workflow.parameters.pvc}}"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: gpu.nvidia.com/class
                  operator: In
                  values:
                    - "{{workflow.parameters.trainer_gpu}}"
                - key: topology.kubernetes.io/region
                  operator: In
                  values:
                    - "{{workflow.parameters.region}}"
    podSpecPatch: |
      containers:
        - name: main
          resources:
            limits:
              nvidia.com/gpu: "{{inputs.parameters.gpu_count}}"
            requests:
              nvidia.com/gpu: "{{inputs.parameters.gpu_count}}"

  - name: serializer
    inputs:
      parameters:
        - name: model
        - name: output_path
    container:
      image: "{{workflow.parameters.serializer_image}}:{{workflow.parameters.serializer_tag}}"
      command: ["python3", "/app/serialize.py"]
      args:
        - "--model-id={{inputs.parameters.model}}"
        - "--save-path={{inputs.parameters.output_path}}"
      resources:
        requests:
          cpu: 1
          memory: 12Gi
        limits:
          cpu: 1
          memory: 12Gi
      volumeMounts:
        - mountPath: "/{{workflow.parameters.pvc}}"
          name: "{{workflow.parameters.pvc}}"
    volumes:
      - name: "{{workflow.parameters.pvc}}"
        persistentVolumeClaim:
           claimName: "{{workflow.parameters.pvc}}"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: topology.kubernetes.io/region
                  operator: In
                  values:
                    - "{{workflow.parameters.region}}"

  
  - name: model-inference-service
    inputs:
      parameters:
        - name: model_id
        - name: hf_home
        - name: command
    resource:
      action: apply
      manifest: |
        apiVersion: serving.kubeflow.org/v1beta1
        kind: InferenceService
        metadata:
          name: inference-{{ workflow.parameters.run_name }}
          annotations:
            autoscaling.knative.dev/scaleToZeroPodRetentionPeriod: 20m
        spec:
          predictor:
            minReplicas: 0
            maxReplicas: 1
            affinity:
              nodeAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                  nodeSelectorTerms:
                    - matchExpressions:
                        - key: gpu.nvidia.com/class
                          operator: In
                          values:
                            - "{{workflow.parameters.inference_gpu}}"
                        - key: topology.kubernetes.io/region
                          operator: In
                          values:
                            - "{{workflow.parameters.region}}"
            containers:
              - name: kfserving-container
                image: "{{workflow.parameters.inference_image}}:{{workflow.parameters.inference_tag}}"
                imagePullPolicy: IfNotPresent
                command: {{inputs.parameters.command}}
                env:
                  - name: STORAGE_URI
                    value: pvc://{{ workflow.parameters.pvc }}/
                  - name: MODEL_ID
                    value: "{{ inputs.parameters.model_id }}"
                  - name: HF_HOME
                    value: "{{ inputs.parameters.hf_home }}"
                resources:
                  requests:
                    nvidia.com/gpu: 1
                    cpu: 4
                    memory: 8Gi
                  limits:
                    nvidia.com/gpu: 1
                    cpu: 12
                    memory: 60Gi
