apiVersion: batch/v1
kind: Job
metadata:
  name: prepare-neox-dataset
spec:
  template:
    spec:
      containers:
        - name: prepare-neox-dataset
          image: navarrepratt/gpt-neox:3
          imagePullPolicy: IfNotPresent
          command: [ "python", "prepare_data.py" ]
          args:
            - -d
            - /mnt/data/datasets
            - -t
            - HFTokenizer
            - --vocab-file
            - /mnt/checkpoints/20B_checkpoints/20B_tokenizer.json
            - hackernews  # All options are here: https://github.com/EleutherAI/gpt-neox/blob/main/tools/corpora.py#L298
          volumeMounts:
            - name: neox-data
              mountPath: /mnt/data
            - name: neox-checkpoints
              mountPath: /mnt/checkpoints
          resources:
            requests:
              cpu: "8"
              memory: 16Gi
            limits:
              cpu: "8"
              memory: 16Gi
      volumes:
        - name: neox-data
          persistentVolumeClaim:
            claimName: neox-data
        - name: neox-checkpoints
          persistentVolumeClaim:
            claimName: neox-checkpoints
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: topology.kubernetes.io/region
                    operator: In
                    values:
                      - LAS1
      restartPolicy: Never
  backoffLimit: 2
