apiVersion: apps/v1
kind: Deployment
metadata:
  name: tensorflow-jupyter
spec:
  strategy:
    type: Recreate
  # Replicas controls the number of instances of the Pod to maintain running at all times
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: tensorflow-jupyter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: tensorflow-jupyter
    spec:
      containers:
        - name: tf
          image: tensorflow/tensorflow:2.0.1-gpu-py3-jupyter

          ports:
            - name: notebook
              containerPort: 8888
              protocol: TCP

          readinessProbe:
            tcpSocket:
              port: notebook
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /
              port: notebook
            initialDelaySeconds: 15
            periodSeconds: 15
            failureThreshold: 3
            timeoutSeconds: 10

          volumeMounts:
            - name: storage
              mountPath: /tf/notebooks
            - name: model-storage
              mountPath: /models

          resources:
            requests:
              cpu: 500m # The CPU unit is mili-cores. 500m is 0.5 cores
              memory: 2048Mi
            limits:
              # GPUs can only be allocated as a limit, which both reserves and limits the number of GPUs the Pod will have access to
              # Making individual Pods resource light is advantageous for bin-packing. In the case of Jupyter, we stick to two GPUs for
              # demonstration purposes
              nvidia.com/gpu: 1

      # Node affinity can be used to require / prefer the Pods to be scheduled on a node with a specific hardware type
      # No affinity allows scheduling on all hardware types that can fulfill the resource request.
      # In this example, without affinity, any NVIDIA GPU would be allowed to run the Pod.
      # Read more about affinity at: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
      affinity:
        nodeAffinity:
          # This will REQUIRE the Pod to be run on a system with a GPU with 8GB VRAM
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu.nvidia.com/vram
                operator: In
                values:
                  - "8"

          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 10
              preference:
                matchExpressions:
                - key: cpu.coreweave.cloud/family
                  operator: In
                  values:
                    - i5
                    - i7
                    - i9
                    - xeon
                    - ryzen
          
      volumes:
        - name: storage
          persistentVolumeClaim:
            claimName: jupyter-pv-claim
        - name: model-storage
          persistentVolumeClaim:
            claimName: model-storage
      restartPolicy: Always
