apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  labels:
    qos.coreweave.cloud/latency: low
  name: tensorizer-kserve-isvc
spec:
  predictor:
    maxReplicas: 100
    minReplicas: 1
    containerConcurrency: 1
    containers:
    - name: tensorizer-gptj
      image: rtalaricw/gpt-tensorizer-pvc@sha256:fbf0d7f356e3aa71fca03dd63bafda6e9e78ce5232ae28e98cd1d0f2327b381f
      env:
        - name: STORAGE_URI 
          value: pvc://model-storage/
      readinessProbe: null
      livenessProbe: null
      resources:
        requests:
          cpu: 8
          memory: 64Gi
          nvidia.com/gpu: 1
        limits:
          cpu: 8
          memory: 64Gi
          nvidia.com/gpu: 1
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: gpu.nvidia.com/class
              operator: In
              values:
                - A40
            - key: topology.kubernetes.io/region
              operator: In
              values:
                - LAS1
            # - key: node.coreweave.cloud/version
            #   operator: NotIn
            #   values:
            #     - 1.20.0
            #     - 1.19.1
            #     - 1.18.0   