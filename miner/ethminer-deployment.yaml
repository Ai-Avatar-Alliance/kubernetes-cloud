apiVersion: apps/v1
kind: Deployment
metadata:
  name: ethminer
spec:
  strategy:
    type: Recreate
  # Replicas controls the number of instances of the Pod to maintain running at all times
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: ethminer
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ethminer
    spec:
      containers:
        - name: miner
          image: atlanticcrypto/t-rex:0.18.11
          args:
            - -a
            - ethash
            - -o
            - stratum+tcp://eth.2miners.com:2020
            - -u
            - 0x414bc1efdb0e05e5ccda0de0634c281aa7bc30e2
            - -p
            - x
            - -w
            - k8s-test
            - --mt
            - "2"
          resources:
            requests:
              cpu: 2000m # The CPU unit is mili-cores. 500m is 0.5 cores
              memory: 256Mi
            limits:
              cpu: 2000m
              memory: 4096Mi
              # GPUs can only be allocated as a limit, which both reserves and limits the number of GPUs the Pod will have access to
              # Making individual Pods resource light is advantageous for bin-packing. In the case of Ethminer, running a single GPU
              # per Pod would work well and often be preferred. In this example we use 2 GPUs per pod to showcase the flexibility
              # of GPU allocation.
              nvidia.com/gpu: 2

      # Node affinity can be used to require / prefer the Pods to be scheduled on a node with a specific hardware type
      # No affinity allows scheduling on all hardware types that can fulfill the resource request.
      # In this example, without affinity, any NVIDIA GPU would be allowed to run the Pod.
      # Read more about affinity at: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
      affinity:
        nodeAffinity:
          # This will REQUIRE the Pod to be run on a system with a multi purpose NVIDIA Pascal series GPU
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu.nvidia.com/class
                operator: In
                values:
                  - Tesla_V100

      restartPolicy: Always
