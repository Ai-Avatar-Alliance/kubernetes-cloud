apiVersion: v1
kind: Pod
metadata:
  name: sshd-demo
  labels:
    app.kubernetes.io/name: sshd
    app.kubernetes.io/instance: demo
spec:
  containers:
  - name: sshd
    image: atlanticcrypto/cuda-ssh-server
    command: ["/bin/bash"]
    args: ["-c", "echo 'root:changeThePasswordAcc' | chpasswd; /usr/sbin/sshd -D"]
    ports:
      - name: sshd
        containerPort: 22
        protocol: TCP
    volumeMounts:
    - name: storage
      mountPath: /root
    resources:
      requests:
        cpu: 500m # The CPU unit is mili-cores. 500m is 0.5 cores
        memory: 1Gi
      limits:
        cpu: 2000m
        memory: 4Gi
        # GPUs can only be allocated as a limit, which both reserves and limits the number of GPUs the Pod will have access to
        # Making individual Pods resource light is advantageous for bin-packing. Since this Pod is for general purpose interactive testing
        # we allocate 6 GPUs to it
        nvidia.com/gpu: 6

  # Node affinity can be used to require / prefer the Pods to be scheduled on a node with a specific hardware type
  # No affinity allows scheduling on all hardware types that can fulfill the resource request.
  # In this example, without affinity, any NVIDIA GPU would be allowed to run the Pod.
  # Read more about affinity at: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity:
    nodeAffinity:
      # This will REQUIRE the Pod to be run on a system with a 1070 Ti, 1080 Ti or P104-100 GPU
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: gpu.nvidia.com/model
            operator: In
            values:
              - GeForce_GTX_1070_Ti
              - GeForce_GTX_1080_Ti
              - P104-100
          - key: failure-domain.beta.kubernetes.io/region
            operator: In
            values:
              - ORD1

  volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: sshd-pv-claim
  restartPolicy: Always
