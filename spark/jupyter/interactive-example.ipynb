{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8ceb8-e788-4fd4-97f4-aac3c79e41cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyspark img2dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a32f009-a31b-4b8e-8109-ccae087ab4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6e604-a3f7-4310-9a85-a1022d2bd0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Update with your namespace\n",
    "NAMESPACE = \"tenant-CHANGE-ME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SERVICE_NAME = \"spark-jupyter\"\n",
    "SERVICE_ACCOUNT_NAME = \"spark-sa\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54559c2b-b4f8-4a82-9bc0-9e0c84b56750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HOSTNAME = !hostname\n",
    "HOSTNAME = HOSTNAME[0]\n",
    "HOSTNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9165fb-37a3-4f3e-b628-f2b63d7684c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "K8S_API = os.environ[\"KUBERNETES_SERVICE_HOST\"]\n",
    "K8S_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028c48c-9753-46b3-b5d3-276ef7dcb03c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "WANDB_API_KEY = os.environ[\"WANDB_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46761ee-4f21-407e-88be-f21fcd4b4fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%!\n",
    "echo 'apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: cpu-job\n",
    "spec:\n",
    "  terminationGracePeriodSeconds: 10\n",
    "  containers:\n",
    "    - name: cpu-job\n",
    "      volumeMounts:\n",
    "        - mountPath: /dev/shm\n",
    "          name: dshm\n",
    "        - name: spark-pvc\n",
    "          # Match the mountPath of jupyter lab\n",
    "          mountPath: /mnt/pvc\n",
    "          readOnly: false\n",
    "\n",
    "  affinity:\n",
    "    nodeAffinity:\n",
    "      requiredDuringSchedulingIgnoredDuringExecution:\n",
    "        nodeSelectorTerms:\n",
    "          - matchExpressions:\n",
    "              - key: topology.kubernetes.io/region\n",
    "                operator: In\n",
    "                values:\n",
    "                  - \"LGA1\"\n",
    "              - key: node.coreweave.cloud/cpu\n",
    "                operator: In\n",
    "                values:\n",
    "                  - amd-epyc-rome\n",
    "                  - amd-epyc-milan\n",
    "                  - intel-xeon-v3\n",
    "                  - intel-xeon-v4\n",
    "  volumes:\n",
    "    - name: dshm\n",
    "      emptyDir:\n",
    "        medium: Memory\n",
    "    - name: spark-pvc\n",
    "      persistentVolumeClaim:\n",
    "        claimName: spark-pvc\n",
    "        readOnly: false\n",
    "  restartPolicy: Always' >> cpu-pod-template.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbcf92-3328-4471-9a04-652e62e607b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"interactive-test\")\n",
    "    .config(\"spark.master\", f\"k8s://{K8S_API}\")\n",
    "    .config(\"spark.submit.deployMode\", \"client\")\n",
    "    .config(\"spark.driver.port\", \"2222\")\n",
    "    .config(\"spark.driver.blockManager.port\", \"7777\")\n",
    "    .config(\"spark.driver.host\", f\"{SERVICE_NAME}.{NAMESPACE}.svc.tenant.chi.local\")\n",
    "    .config(\"spark.ui.port\", \"4040\")\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "\n",
    "    # Driver config (Resources should match the deployment)\n",
    "    .config(\"spark.driver.cores\", \"16\")\n",
    "    .config(\"spark.kubernetes.driver.limit.cores\", \"16\")\n",
    "    .config(\"spark.driver.memory\", \"64G\")\n",
    "    .config(\"spark.kubernetes.driver.pod.name\", HOSTNAME)\n",
    "\n",
    "    # Executor config\n",
    "    .config(\"spark.executor.cores\", \"16\")\n",
    "    .config(\"spark.kubernetes.executor.limit.cores\", \"16\")\n",
    "    .config(\"spark.executor.memory\", \"64G\")\n",
    "    .config(\"spark.kubernetes.executor.podNamePrefix\", \"spark-interactive\")\n",
    "\n",
    "    # Dynamic scaling config\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"0\")\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"5\")\n",
    "    # .config(\"spark.executor.instances\", 5)\n",
    "\n",
    "    # The image has spark v3.4.0 and img2dataset already installed\n",
    "    .config(\"spark.kubernetes.driver.container.image\", \"navarrepratt/spark-download-imgdataset:1.0.0\")\n",
    "    .config(\"spark.kubernetes.executor.container.image\", \"navarrepratt/spark-download-imgdataset:1.0.0\")\n",
    "\n",
    "    # Use the pod template that was defined in a local file in the previous cell\n",
    "    .config(\"spark.kubernetes.driver.podTemplateFile\", \"./cpu-pod-template.yaml\")\n",
    "    .config(\"spark.kubernetes.executor.podTemplateFile\", \"./cpu-pod-template.yaml\")\n",
    "\n",
    "    .config(\"spark.kubernetes.namespace\", NAMESPACE)\n",
    "    .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", SERVICE_ACCOUNT_NAME)\n",
    "    .config(\"spark.kubernetes.authenticate.serviceAccountName\", SERVICE_ACCOUNT_NAME)\n",
    "\n",
    "    .config(\"spark.kubernetes.driverEnv.WANDB_API_KEY\", WANDB_API_KEY)\n",
    "    .config(\"spark.executorEnv.WANDB_API_KEY\", WANDB_API_KEY)\n",
    "\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57948b-39e8-44f7-b5d3-ffa467bc3d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example workload to calculate Pi\n",
    "# Meant to spin up all 5 of the dynamic executors defined above.\n",
    "\n",
    "from random import random\n",
    "from operator import add\n",
    "\n",
    "partitions = 100\n",
    "n = 10000000 * partitions\n",
    "\n",
    "def f(_):\n",
    "    x = random() * 2 - 1\n",
    "    y = random() * 2 - 1\n",
    "    return 1 if x ** 2 + y ** 2 <= 1 else 0\n",
    "\n",
    "count = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n",
    "print(\"Pi is roughly %f\" % (4.0 * count / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86010d3d-87d5-4024-9df7-61fe223be201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/conceptual_12m/cc12m.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b095a66-1003-4042-b03f-20ea9269ca25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sed -i '1s/^/url\\tcaption\\n/' cc12m.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Downlowd the CC12M dataset to the PVC.\n",
    "# Should take ~1 hour.\n",
    "\n",
    "from img2dataset import download\n",
    "\n",
    "url_list = \"/mnt/pvc/cc12m.tsv\"\n",
    "output = \"/mnt/pvc/cc12m-jupyter\"\n",
    "thread_count = 2048\n",
    "\n",
    "download(\n",
    "    processes_count=1,  # Process count will be num executors * num cores per executor when using pyspark\n",
    "    thread_count=thread_count,\n",
    "    url_list=url_list,\n",
    "    image_size=256,\n",
    "    output_folder=output,\n",
    "    output_format=\"webdataset\",\n",
    "    input_format=\"tsv\",\n",
    "    url_col=\"url\",\n",
    "    caption_col=\"caption\",\n",
    "    enable_wandb=True,\n",
    "    subjob_size=10000,\n",
    "    distributor=\"pyspark\",\n",
    "    timeout=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
